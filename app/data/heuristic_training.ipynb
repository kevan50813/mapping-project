{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pygeodesy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "from pygeodesy.sphericalNvector import LatLon, Nvector\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import timeit\n",
    "from threading import Thread\n",
    "from multiprocess import Process, Pool\n",
    "from itertools import repeat\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90BrOG9Oek9X"
   },
   "outputs": [],
   "source": [
    "# load in the sqlite file into memory\n",
    "\n",
    "db_file= \"scan_data.sqlite\"\n",
    "\n",
    "# basic setup\n",
    "con = sqlite3.connect(db_file)\n",
    "con.row_factory = sqlite3.Row\n",
    "cur = con.cursor()\n",
    "\n",
    "# join on the ID, as the base geometry BLOB in the ScanData table is raw binary\n",
    "# we could convert that to geomtry via a QGIS package for JSON, but joining works just as well\n",
    "db_rows = con.execute(\n",
    "    \"SELECT ScanData.pkuid, ScanData.data, ScanData.level, \\\n",
    "    idx_ScanData_geometry.xmin, idx_ScanData_geometry.xmax, idx_ScanData_geometry.ymin, idx_ScanData_geometry.ymax \\\n",
    "    FROM ScanData \\\n",
    "    INNER JOIN idx_ScanData_geometry \\\n",
    "    ON ScanData.pkuid=idx_ScanData_geometry.pkid\"\n",
    ")\n",
    "# turn it into our favourite thing ever, a dictionary :)\n",
    "db_dict = [dict(row) for row in db_rows]\n",
    "print(f\"Obtained {len(db_dict)} rows from database.\")\n",
    "\n",
    "# ensure the connection is closed\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the AP locational data for referencing\n",
    "\n",
    "# we dont care about the preamble, so just get the features\n",
    "with open(\"heuristic_nodes.json\", 'r') as f:\n",
    "    node_data = json.load(f)['features']\n",
    "    \n",
    "# will hold the AP locational data for referencing later\n",
    "node_dict = {}\n",
    "\n",
    "# set up dictionary with the MAC as the key, and the level and coordinates as values\n",
    "for entry in node_data:\n",
    "    data = entry['properties']\n",
    "    \n",
    "    # only take Points with a MAC value, i.e. only take APs\n",
    "    if not data['mac_addres'] is None:\n",
    "        \n",
    "        # skim off the last char of the key. still unique. this makes later processing O(1) instead of O(n)\n",
    "        node_dict[data['mac_addres'][:-1]] = {\n",
    "            \"level\": int(data['level']),\n",
    "            \"coordinates\": entry['geometry']['coordinates']\n",
    "        }\n",
    "\n",
    "# sort based on level\n",
    "node_dict = dict(sorted(node_dict.items(), key=lambda x:x[1]['level']))        \n",
    "\n",
    "for mac, data in node_dict.items():\n",
    "    print(f\"MAC {mac} on Level {data['level']} := {data['coordinates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_networks(data, level):\n",
    "    \n",
    "    common_list = []\n",
    "    \n",
    "    for scan in data:\n",
    "        common_scan = []\n",
    "\n",
    "        for network in scan:\n",
    "            mac = network['BSSID'][:-1]\n",
    "            \n",
    "            # get networks of known location on the same floor\n",
    "            try:\n",
    "                entry = node_dict[mac]\n",
    "                if entry['level'] == level:\n",
    "                    \n",
    "                    # ensure the AP hasnt already been added from a similar MAC but same location\n",
    "                    # same location will break trilateration entirely\n",
    "                    if not any(net for net in common_scan if net[\"BSSID\"][:-1] == mac):\n",
    "                        pos = LatLon(entry['coordinates'][0], entry['coordinates'][1])\n",
    "                        network['coordinates'] = pos\n",
    "                        del network[\"SSID\"]\n",
    "                        common_scan.append(network)\n",
    "            except Exception:\n",
    "                ...\n",
    "        \n",
    "        common_list.append(common_scan)\n",
    "            \n",
    "    return common_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# turn sqlite file into dictionary, referencing scan data against AP dict to add locations\n",
    "\n",
    "# the end dict that will hold all data for trilateration\n",
    "ap_dict = {}\n",
    "\n",
    "for row in db_dict:\n",
    "    \n",
    "    # point is a circle defined by bounding box - get center\n",
    "    x = (row['xmin'] + row['xmax']) / 2\n",
    "    y = (row['ymin'] + row['ymax']) / 2\n",
    "    \n",
    "    # main key for this dict will be by floor\n",
    "    level = row['level']\n",
    "    if not level in ap_dict:\n",
    "        ap_dict[level] = {}\n",
    "    \n",
    "    # augment scan data with positional data for each scanned AP\n",
    "    ap_dict[level][(x, y)] = compare_networks(json.loads(row['data']), level)\n",
    "    \n",
    "# sort based on floor, and display end message\n",
    "ap_dict = dict(sorted(ap_dict.items()))\n",
    "print(f\"Dict created, with {len(ap_dict)} keys with the following value lengths: \\\n",
    "{[len(val) for val in ap_dict.values()]}\\n\")\n",
    "\n",
    "for level, level_data in ap_dict.items():\n",
    "    print(f\"Level {level}\")\n",
    "    for geometry, scan in level_data.items():\n",
    "        print(f\"{geometry} := net count/scan: {[len(s) for s in scan]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste of the EXACT trilateration algo used in jsgeodesy\n",
    "# the python implementation is different! so we use this one\n",
    "\n",
    "point_nvectors = {}\n",
    "def trilaterate(point1, distance1, point2, distance2, point3, distance3, radius=6371e3, point_nvectors=point_nvectors, Nvector=Nvector):\n",
    "        # from en.wikipedia.org/wiki/Trilateration\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            n1 = point_nvectors[(point1.lat, point1.lon)]\n",
    "        except KeyError:\n",
    "            n1 = point1.toNvector()\n",
    "            point_nvectors[(point1.lat, point1.lon)] = n1\n",
    "        \n",
    "        try:\n",
    "            n2 = point_nvectors[(point2.lat, point2.lon)]\n",
    "        except KeyError:\n",
    "            n2 = point2.toNvector()\n",
    "            point_nvectors[(point2.lat, point2.lon)] = n2\n",
    "        \n",
    "        try:\n",
    "            n3 = point_nvectors[(point3.lat, point3.lon)]\n",
    "        except KeyError:\n",
    "            n3 = point3.toNvector()\n",
    "            point_nvectors[(point3.lat, point3.lon)] = n3\n",
    "        \n",
    "        δ1 = distance1/radius\n",
    "        δ2 = distance2/radius\n",
    "        δ3 = distance3/radius\n",
    "\n",
    "        # the following uses x,y coordinate system with origin at n1, x axis n1->n2\n",
    "        eX = n2.minus(n1).unit()                         # unit vector in x direction n1->n2\n",
    "        i = eX.dot(n3.minus(n1))                         # signed magnitude of x component of n1->n3\n",
    "        eY = n3.minus(n1).minus(eX.times(i)).unit()      # unit vector in y direction\n",
    "        d = n2.minus(n1).length                          # distance n1->n2\n",
    "        j = eY.dot(n3.minus(n1))                         # signed magnitude of y component of n1->n3\n",
    "        x = (δ1*δ1 - δ2*δ2 + d*d) / (2*d)                # x component of n1 -> intersection\n",
    "        y = (δ1*δ1 - δ3*δ3 + i*i + j*j) / (2*j) - x*i/j  # y component of n1 -> intersection\n",
    "        # const eZ = eX.cross(eY);                            # unit vector perpendicular to plane\n",
    "        # const z = Math.sqrt(δ1*δ1 - x*x - y*y);             # z will be NaN for no intersections\n",
    "\n",
    "        n = n1.plus(eX.times(x)).plus(eY.times(y)) # note don't use z component; assume points at same height\n",
    "\n",
    "        return Nvector(n.x, n.y, n.z).toLatLon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the formula we're tuning!\n",
    "# rssiToDistance in Trilateration.js\n",
    "def rssi_to_distance(A, n, RSSI, math=math):\n",
    "    dist = math.pow(10, ((RSSI - A) / (-10 * n)))\n",
    "    return dist\n",
    "\n",
    "# trilaterate in Trilateration.js\n",
    "def do_trilaterate(A, n, triplet, rssi_to_distance=rssi_to_distance, trilaterate=trilaterate):\n",
    "    \n",
    "    #points = [LatLon(net['coordinates'][0], net['coordinates'][1]) for net in triplet]\n",
    "    points = [net['coordinates'] for net in triplet]\n",
    "    distances = [rssi_to_distance(A, n, net['RSSI']) for net in triplet]\n",
    "    \n",
    "    try:\n",
    "        point = trilaterate(\n",
    "            points[0],\n",
    "            distances[0],\n",
    "            points[1],\n",
    "            distances[1],\n",
    "            points[2],\n",
    "            distances[2]\n",
    "        )\n",
    "        \n",
    "        pointArr = [point.lat, point.lon]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pointArr = [-1, -1]\n",
    "        \n",
    "    return pointArr\n",
    "\n",
    "def distance(point1, point2, math=math):\n",
    "    return math.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# distance in Trilateration.js\n",
    "def meter_distance(point1, point2):\n",
    "    return point1.distanceTo(point2)\n",
    "    #return math.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n",
    "\n",
    "# getStats in Trilateration.js\n",
    "def get_stats(data, distance=distance, math=math):\n",
    "    pointSum = [sum(i) for i in zip(*data)]\n",
    "    \n",
    "    avg = [pointSum[0] / len(data), pointSum[1] / len(data)]\n",
    "    sumErrSq = sum([distance(point, avg) ** 2 for point in data])\n",
    "    \n",
    "    variance = sumErrSq / len(data)\n",
    "    sd = math.sqrt(variance)\n",
    "    \n",
    "    return avg, sd\n",
    "\n",
    "\n",
    "def iterate_all(A, n, networks, do_trilaterate=do_trilaterate, get_stats=get_stats, distance=distance):\n",
    "    \n",
    "    allPoints = []\n",
    "    \n",
    "    for i in range(len(networks) - 2):\n",
    "        for j in range(i + 1, len(networks) - 1):\n",
    "            for k in range(j + 1, len(networks)):\n",
    "                triplet = [networks[i], networks[j], networks[k]]\n",
    "                data = do_trilaterate(A, n, triplet)\n",
    "                \n",
    "                if data[0] != -1:\n",
    "                    allPoints.append(data)\n",
    "                    \n",
    "    sdCount = 2\n",
    "    pointDifference = 999\n",
    "\n",
    "    while pointDifference != 0:\n",
    "        originalPointCount = len(allPoints)\n",
    "        avg, sd = get_stats(allPoints)\n",
    "        \n",
    "        newPoints = [point for point in allPoints if distance(avg, point) < sdCount * sd]\n",
    "        pointDifference = originalPointCount - len(newPoints)\n",
    "        \n",
    "        if pointDifference != len(allPoints):\n",
    "            allPoints = newPoints\n",
    "        else:\n",
    "            pointDifference = 0\n",
    "            \n",
    "    pointSum = [sum(i) for i in zip(*allPoints)]\n",
    "    \n",
    "    return [pointSum[0] / len(allPoints), pointSum[1] / len(allPoints)]\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets and processes error for the chosen scan location/floor/all data\n",
    "def err_controller(A, n, ap_dict=ap_dict, iterate_all=iterate_all, meter_distance=meter_distance, LatLon=LatLon):\n",
    "    err_bound = (0, 10)\n",
    "    error_per_point = []\n",
    "    levels = [2]\n",
    "    \n",
    "    lat_lons = {}\n",
    "    \n",
    "    # for each level we want to do this on...\n",
    "    for level in levels:\n",
    "        level_data = ap_dict[level]\n",
    "        \n",
    "        # for each sample location... (10 per floor 0:3, 6 on floor 4, 3 on floor 5)        \n",
    "        for actual_point, scans in level_data.items():\n",
    "            actual_point = tuple(actual_point)\n",
    "            if actual_point in lat_lons:\n",
    "                actual_point_ll = lat_lons[actual_point]\n",
    "            else:\n",
    "                actual_point_ll = LatLon(*actual_point)\n",
    "                lat_lons[actual_point] = actual_point_ll\n",
    "            \n",
    "            # for each of the 10 scans in that location...\n",
    "            err_total = 0.0\n",
    "            \n",
    "            for scan in scans:\n",
    "                \n",
    "                # get the calculated location using trilat, and get dist to actual point\n",
    "                predicted_point = iterate_all(A, n, scan)\n",
    "                predicted_point = tuple(predicted_point)\n",
    "                \n",
    "                if predicted_point in lat_lons:\n",
    "                    predicted_point_ll = lat_lons[predicted_point]\n",
    "                else:\n",
    "                    predicted_point_ll = LatLon(*predicted_point)\n",
    "                    lat_lons[predicted_point] = predicted_point_ll\n",
    "                \n",
    "                err = meter_distance(predicted_point_ll, actual_point_ll)\n",
    "                \n",
    "                # error function?\n",
    "                err_total += err\n",
    "            \n",
    "            # average over each scan\n",
    "            err_total = err_total / len(scans)\n",
    "            error_per_point.append(err_total)\n",
    "                \n",
    "    err_avg = sum(error_per_point) / len(error_per_point)\n",
    "    \n",
    "    if err_avg < err_bound[0]:\n",
    "        err_avg = err_bound[0]\n",
    "    if err_avg > err_bound[1]:\n",
    "        err_avg = err_bound[1]\n",
    "    \n",
    "    return (err_avg, error_per_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that obtains all the Z axis data, for a given A/n\n",
    "def f_trilat_pool(A_space, n_space):\n",
    "    \n",
    "    Z = []\n",
    "    min_err = {'err': 9999, 'A': -1, 'n': -1, 'errors': []}\n",
    "    for A_i, A in enumerate(A_space):\n",
    "        \n",
    "        print(f\"Working on A {A_i+1}/{A_div} - Executing processes...\")\n",
    "        \n",
    "        with Pool() as pool:\n",
    "            data = pool.starmap(err_controller, zip(repeat(A), n_space))\n",
    "        \n",
    "        Z_sub = [tup[0] for tup in data]        \n",
    "        \n",
    "        print(f\"Processes concluded.\") \n",
    "\n",
    "        for idx, err in enumerate(Z_sub):\n",
    "            if err < min_err['err']:\n",
    "                min_err['err'] = err\n",
    "                min_err['A'] = A\n",
    "                min_err['n'] = n_space[idx]\n",
    "                min_err['errors'] = data[idx][1]\n",
    "        \n",
    "        Z.append(Z_sub)\n",
    "        \n",
    "        \n",
    "    print(f\"\\nMin err of {min_err['err']} at (A: {min_err['A']}; n: {min_err['n']})\")\n",
    "    print(f\"Error at each scan: {[round(err, 1) for err in min_err['errors']]}\")\n",
    "    \n",
    "    return np.array(Z).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on A 1/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 2/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 3/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 4/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 5/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 6/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 7/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 8/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 9/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 10/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 11/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 12/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 13/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 14/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 15/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 16/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 17/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 18/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 19/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 20/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 21/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 22/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 23/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 24/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 25/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 26/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 27/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 28/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 29/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 30/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 31/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 32/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 33/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 34/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 35/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 36/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 37/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 38/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 39/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 40/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 41/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 42/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 43/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 44/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 45/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 46/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 47/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 48/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 49/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 50/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 51/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 52/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 53/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 54/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 55/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 56/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 57/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 58/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 59/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 60/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 61/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 62/64 - Executing processes...\n",
      "Processes concluded.\n",
      "Working on A 63/64 - Executing processes...\n"
     ]
    }
   ],
   "source": [
    "A_div = 64\n",
    "n_div = 64\n",
    "A = np.linspace(50, -100, A_div)\n",
    "n = np.linspace(2, 10, n_div)\n",
    "\n",
    "toc = timeit.default_timer()\n",
    "Z = f_trilat_pool(A, n)\n",
    "tic = timeit.default_timer()\n",
    "\n",
    "print(f\"Time taken to process: {tic - toc}s\")\n",
    "\n",
    "A, n = np.meshgrid(A, n)\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlabel(\"A\")\n",
    "ax.set_ylabel(\"n\")\n",
    "ax.set_zlabel(\"Error (m)\")\n",
    "ax.plot_surface(A, n, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Huristic_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
